{
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de617687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime, timedelta\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf2096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unix datetime\n",
    "base = pd.Timestamp(\"1970-01-01\")\n",
    "CHUNK_SIZE = 1000000\n",
    "REVIEW_DROP = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e91825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extract keys from the nested dictionary\n",
    "def extract_keys(attr, key):\n",
    "    if attr == None:\n",
    "        return \"{}\"\n",
    "    if key in attr:\n",
    "        return attr.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6740084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to dictionary\n",
    "def str_to_dict(attr):\n",
    "    if attr != None:\n",
    "        return ast.literal_eval(attr)\n",
    "    else:\n",
    "        return ast.literal_eval(\"{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e39ac00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_timestamp(element):\n",
    "    element = element[0]\n",
    "    a, b = element.split('-')\n",
    "    a = datetime.strptime(a, \"%H:%M\")\n",
    "    b = datetime.strptime(b, \"%H:%M\")\n",
    "    return timedelta.total_seconds(b - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05ff3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether CUDA (GPU acceleration) is available on the current system\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "# convert the values of the DataFrame to a PyTorch tensor\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).long().to(device)\n",
    "\n",
    "# converts a pandas DataFrame to a PyTorch tensor\n",
    "def df_to_tensor_cpu(df):\n",
    "    return torch.from_numpy(df.values).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173b4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_chunk(reviews, users, restaurants):\n",
    "    reviews = pd.merge(reviews, users, how='inner', on='user_id')\n",
    "    reviews = reviews.drop(columns='user_id')\n",
    "    reviews = pd.merge(reviews, restaurants, how='inner', on='business_id')\n",
    "    reviews = reviews.drop(columns='business_id')\n",
    "    print(\"REVIEWS.HEAD() -------------------------------------------------------------------\")\n",
    "    print(reviews.head())\n",
    "    reviews = reviews.drop(columns=reviews.columns[0], axis=1)\n",
    "    print(\"REVIEWS.DROP() -------------------------------------------------------------------\")\n",
    "    print(reviews.head())\n",
    "    return df_to_tensor(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b739279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_percent, val_percent, test_percent):\n",
    "    print(\"Reading users\")\n",
    "    with open('dataset\yelp_academic_dataset_user.json', 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "\n",
    "    users = pd.DataFrame(data)\n",
    "    users = users[users['review_count'] > REVIEW_DROP]\n",
    "    users['user_id'] = users['user_id'].astype('category')\n",
    "    users['user_id_num'] = users['user_id'].cat.codes\n",
    "    users = users[['user_id', 'user_id_num', 'review_count']]\n",
    "    user_id_to_num = dict(zip(users['user_id'], users['user_id_num']))\n",
    "\n",
    "    print(\"Reading businesses\")\n",
    "    with open('dataset\yelp_academic_dataset_business.json', 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "\n",
    "    restaurants = pd.DataFrame(data)\n",
    "    restaurants['business_id'] = restaurants['business_id'].astype('category')\n",
    "    restaurants['business_id_num'] = restaurants['business_id'].cat.codes\n",
    "    restaurants = restaurants[['business_id', 'business_id_num']]\n",
    "    rest_id_to_num = dict(zip(restaurants['business_id'], restaurants['business_id_num']))\n",
    "\n",
    "    print(\"Reading reviews\")\n",
    "    with open('dataset\yelp_academic_dataset_review.json', 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "\n",
    "    reviews = pd.DataFrame(data)\n",
    "\n",
    "    reviews = pd.merge(reviews, users, how='inner', on='user_id')\n",
    "    reviews = reviews.drop(columns='user_id')\n",
    "    reviews = pd.merge(reviews, restaurants, how='inner', on='business_id')\n",
    "    reviews = reviews.drop(columns=['business_id', 'text','review_id','date'])\n",
    "    print(\"REVIEWS.HEAD() -------------------------------------------------------------------\")\n",
    "    print(reviews.head())\n",
    "    reviews = reviews.drop(columns=reviews.columns[0], axis=1)\n",
    "    print(\"REVIEWS.DROP() -------------------------------------------------------------------\")\n",
    "    print(reviews.head())\n",
    "\n",
    "    pickle.dump(user_id_to_num, open('../dataset/user_id_to_num.pkl', 'wb'))\n",
    "    pickle.dump(rest_id_to_num, open('../dataset/rest_id_to_num.pkl', 'wb'))\n",
    "    np.save('../dataset/data.npy', reviews.values)\n",
    "\n",
    "    training = reviews.sample(frac=train_percent)\n",
    "\n",
    "    left = reviews.drop(training.index)\n",
    "    validation = left.sample(frac=val_percent / (val_percent + test_percent))\n",
    "\n",
    "    test = left.drop(validation.index)\n",
    "\n",
    "    print(\"loaded\")\n",
    "\n",
    "    return df_to_tensor_cpu(training), df_to_tensor_cpu(validation), df_to_tensor_cpu(test), user_id_to_num, rest_id_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03821e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading users\n",
      "Reading businesses\n",
      "Reading reviews\n",
      "REVIEWS.HEAD() -------------------------------------------------------------------\n",
      "   stars  useful  funny  cool  user_id_num  review_count  business_id_num\n",
      "0    3.0       0      0     0      1575913            33            80739\n",
      "1    2.0       0      0     0       194076            39            80739\n",
      "2    5.0       0      0     0      1679313             7            80739\n",
      "3    3.0       0      0     0      1888226           490            80739\n",
      "4    2.0       8      0     0       758236           483            80739\n",
      "REVIEWS.DROP() -------------------------------------------------------------------\n",
      "   useful  funny  cool  user_id_num  review_count  business_id_num\n",
      "0       0      0     0      1575913            33            80739\n",
      "1       0      0     0       194076            39            80739\n",
      "2       0      0     0      1679313             7            80739\n",
      "3       0      0     0      1888226           490            80739\n",
      "4       8      0     0       758236           483            80739\n",
      "loaded\n",
      "TRAIN ----------------------------------------------\n",
      "torch.Size([4194115, 6])\n",
      "VAL ----------------------------------------------\n",
      "torch.Size([2097058, 6])\n",
      "TEST ----------------------------------------------\n",
      "torch.Size([699019, 6])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train, val, test, user, rest = load_data(0.6, 0.3, 0.1)\n",
    "    print(\"TRAIN ----------------------------------------------\")\n",
    "    print(train.shape)\n",
    "    print(\"VAL ----------------------------------------------\")\n",
    "    print(val.shape)\n",
    "    print(\"TEST ----------------------------------------------\")\n",
    "    print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b32aa",
   "metadata": {},
   "source": [
    "###  Output data with the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d77464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading users\n",
      "Reading businesses\n",
      "Reading reviews\n"
     ]
    }
   ],
   "source": [
    "# Output data with the text column\n",
    "\n",
    "print(\"Reading users\")\n",
    "with open('yelp_academic_dataset_user.json', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "users = pd.DataFrame(data)\n",
    "users = users[users['review_count'] > REVIEW_DROP]\n",
    "users['user_id'] = users['user_id'].astype('category')\n",
    "users['user_id_num'] = users['user_id'].cat.codes\n",
    "users = users[['user_id', 'user_id_num', 'review_count']]\n",
    "user_id_to_num = dict(zip(users['user_id'], users['user_id_num']))\n",
    "\n",
    "print(\"Reading businesses\")\n",
    "with open('yelp_academic_dataset_business.json', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "restaurants = pd.DataFrame(data)\n",
    "restaurants['business_id'] = restaurants['business_id'].astype('category')\n",
    "restaurants['business_id_num'] = restaurants['business_id'].cat.codes\n",
    "restaurants = restaurants[['business_id', 'business_id_num']]\n",
    "rest_id_to_num = dict(zip(restaurants['business_id'], restaurants['business_id_num']))\n",
    "\n",
    "print(\"Reading reviews\")\n",
    "with open('yelp_academic_dataset_review.json', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "reviews = pd.DataFrame(data)\n",
    "\n",
    "reviews = pd.merge(reviews, users, how='inner', on='user_id')\n",
    "reviews = reviews.drop(columns='user_id')\n",
    "reviews = pd.merge(reviews, restaurants, how='inner', on='business_id')\n",
    "reviews = reviews.drop(columns=['business_id', 'text'])\n",
    "\n",
    "\n",
    "# pickle.dump(user_id_to_num, open('../dataset/user_id_to_num.pkl', 'wb'))\n",
    "# pickle.dump(rest_id_to_num, open('../dataset/rest_id_to_num.pkl', 'wb'))\n",
    "np.save('../dataset/data_text.npy', reviews.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029edb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
